# ğŸ§  CSE 475 Lab Assignment 02: Semi-Supervised & Self-Supervised Learning for Brain MRI Detection

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![YOLO](https://img.shields.io/badge/YOLO-v12-green.svg)](https://github.com/ultralytics/ultralytics)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> **Course**: CSE 475 - Pattern Recognition and Neural Networks  
> **Assignment**: Lab Assignment 02  
> **Topic**: Semi-Supervised & Self-Supervised Learning for Medical Image Analysis

---

## ğŸ“‹ Table of Contents

- [Project Overview](#-project-overview)
- [Key Results Summary](#-key-results-summary)
- [Repository Structure](#-repository-structure)
- [Notebooks Description](#-notebooks-description)
  - [01: Data Preparation & EDA](#1%EF%B8%8Fâƒ£-data-preparation--eda)
  - [02: Semi-Supervised Object Detection (SSOD)](#2%EF%B8%8Fâƒ£-semi-supervised-object-detection-ssod)
  - [03-1: SimCLR Pretraining](#3%EF%B8%8Fâƒ£-simclr-self-supervised-pretraining)
  - [03-2: SimCLR Fine-tuning](#4%EF%B8%8Fâƒ£-simclr-fine-tuning)
  - [04-1: DINOv3 Feature Extraction](#5%EF%B8%8Fâƒ£-dinov3-feature-extraction)
  - [04-2: DINOv3 Fine-tuning](#6%EF%B8%8Fâƒ£-dinov3-fine-tuning)
- [Methodology](#-methodology)
- [Results & Metrics](#-results--metrics)
- [Visualizations](#-visualizations)
- [Installation & Usage](#-installation--usage)
- [Model Weights](#-model-weights)
- [References](#-references)

---

## ğŸ¯ Project Overview

This project implements **Semi-Supervised Learning (SSL)** and **Self-Supervised Learning** techniques for **Brain MRI Object Detection**. The goal is to leverage both labeled and unlabeled medical imaging data to improve detection performance for three brain conditions:

| Class | Description |
|-------|-------------|
| **CCT** | Cerebral Cortex Tumor |
| **IFC** | Intracerebral Fluid Collection |
| **UAS** | Unidentified Anomaly Signature |

### ğŸ”¬ Learning Paradigms Explored

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ASSIGNMENT 2: LEARNING PARADIGMS                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  1ï¸âƒ£ SEMI-SUPERVISED LEARNING (Notebook 02)                              â”‚
â”‚     â””â”€â”€ Pseudo-Labelling with YOLOv12                                   â”‚
â”‚         â€¢ Teacher-Student Framework                                      â”‚
â”‚         â€¢ Confidence Threshold: Ï„ = 0.70                                â”‚
â”‚         â€¢ Labeled: 20% | Unlabeled: 80%                                 â”‚
â”‚                                                                          â”‚
â”‚  2ï¸âƒ£ SELF-SUPERVISED LEARNING - SimCLR (Notebooks 03-1, 03-2)           â”‚
â”‚     â””â”€â”€ Contrastive Learning                                            â”‚
â”‚         â€¢ NT-Xent Loss                                                  â”‚
â”‚         â€¢ ResNet-18 Backbone                                            â”‚
â”‚         â€¢ Linear Eval + Full Fine-tuning                                â”‚
â”‚                                                                          â”‚
â”‚  3ï¸âƒ£ SELF-SUPERVISED LEARNING - DINOv3 (Notebooks 04-1, 04-2)           â”‚
â”‚     â””â”€â”€ Self-Distillation with No Labels v3                            â”‚
â”‚         â€¢ Vision Transformer (ViT-B/16)                                 â”‚
â”‚         â€¢ Feature Extraction + MLP Classification                       â”‚
â”‚         â€¢ YOLOv12 Integration                                           â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ† Key Results Summary

### ğŸ“Š Object Detection Performance (mAP@50)

| Model | mAP@50 | mAP@50-95 | Precision | Recall | F1-Score |
|:------|:------:|:---------:|:---------:|:------:|:--------:|
| **Baseline (100% Data)** | **93.04%** | **64.59%** | 84.66% | 86.55% | 85.59% |
| Teacher (20% Data) | 81.84% | 53.92% | 72.11% | 79.34% | 75.55% |
| Student (Pseudo-Labeled) | 73.66% | 49.55% | 71.19% | 69.08% | 70.12% |
| **DINOv3 + YOLO** | **94.08%** | **67.73%** | 86.33% | 89.49% | **87.88%** |

### ğŸ“ˆ Classification Performance (Test Accuracy)

| Method | Accuracy | Precision | Recall | F1-Score |
|:-------|:--------:|:---------:|:------:|:--------:|
| SimCLR Linear Eval | 58.59% | 56.81% | 58.59% | 54.60% |
| **SimCLR Full Fine-tune** | **90.31%** | **90.33%** | **90.31%** | **90.31%** |
| DINOv3 + MLP | 89.45% | 89.50% | 89.45% | 89.47% |

### ğŸ¯ Per-Class Detection (AP@50)

| Class | Baseline | Teacher | Student | DINOv3+YOLO |
|:------|:--------:|:-------:|:-------:|:-----------:|
| CCT | 95.18% | 77.37% | 76.53% | **96.21%** |
| IFC | 91.89% | 76.30% | 60.15% | **92.45%** |
| UAS | 92.06% | 91.85% | 84.29% | **93.58%** |

---

## ğŸ“ Repository Structure

```
CSE475_Assignment2_SSL/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                                    # This file
â”œâ”€â”€ ğŸ“„ LICENSE                                      # MIT License
â”œâ”€â”€ ğŸ“„ requirements.txt                             # Python dependencies
â”‚
â”œâ”€â”€ ğŸ““ notebooks/                                   # All Jupyter Notebooks
â”‚   â”œâ”€â”€ 01-data-preparation-eda.ipynb              # Data prep & analysis
â”‚   â”œâ”€â”€ 02-ssod-yolo-pseudolabel.ipynb             # Semi-supervised detection
â”‚   â”œâ”€â”€ 03-1-simclr-pretraining.ipynb              # SimCLR pretraining
â”‚   â”œâ”€â”€ 03-2-simclr-finetuning.ipynb               # SimCLR fine-tuning
â”‚   â”œâ”€â”€ 04-1-dinov3-featureextraction.ipynb        # DINOv3 features
â”‚   â””â”€â”€ 04-2-dinov3-finetuning.ipynb               # DINOv3 + YOLO
â”‚
â”œâ”€â”€ ğŸ“š theory/                                      # Detailed theory documentation
â”‚   â”œâ”€â”€ 01_data_preparation_theory.md              # Data & EDA theory
â”‚   â”œâ”€â”€ 02_ssod_pseudolabeling_theory.md           # Semi-supervised theory
â”‚   â”œâ”€â”€ 03_simclr_theory.md                        # SimCLR theory
â”‚   â””â”€â”€ 04_dinov3_theory.md                        # DINOv3 theory
â”‚
â”œâ”€â”€ ğŸ“Š results/                                     # All experimental results
â”‚   â”œâ”€â”€ 01_eda/                                    # EDA visualizations
â”‚   â”œâ”€â”€ 02_ssod/                                   # SSOD results & metrics
â”‚   â”œâ”€â”€ 03_simclr/                                 # SimCLR results
â”‚   â”‚   â”œâ”€â”€ pretraining/                           # Pretraining outputs
â”‚   â”‚   â””â”€â”€ finetuning/                            # Fine-tuning outputs
â”‚   â””â”€â”€ 04_dinov3/                                 # DINOv3 results
â”‚       â”œâ”€â”€ features/                              # Extracted features
â”‚       â””â”€â”€ finetuning/                            # Detection results
â”‚
â”œâ”€â”€ ğŸ‹ï¸ weights/                                    # Model weights
â”‚   â”œâ”€â”€ simclr_backbone.pth                        # Pretrained SimCLR
â”‚   â”œâ”€â”€ simclr_finetuned.pth                       # Fine-tuned SimCLR
â”‚   â”œâ”€â”€ dinov3_mlp_best.pth                        # DINOv3 MLP classifier
â”‚   â””â”€â”€ yolo_detectors/                            # YOLO weights
â”‚       â”œâ”€â”€ baseline_best.pt                       # Baseline YOLO
â”‚       â”œâ”€â”€ ssod_student.pt                        # SSOD student
â”‚       â”œâ”€â”€ simclr_yolo_best.pt                    # SimCLR + YOLO
â”‚       â””â”€â”€ dinov3_yolo_best.pt                    # DINOv3 + YOLO
â”‚
â”œâ”€â”€ ğŸ“ˆ visualizations/                              # Key visualizations
â”‚   â”œâ”€â”€ training_curves/                           # Loss & accuracy plots
â”‚   â”œâ”€â”€ confusion_matrices/                        # Per-model confusion
â”‚   â”œâ”€â”€ tsne_plots/                                # Feature visualizations
â”‚   â”œâ”€â”€ predictions/                               # Sample predictions
â”‚   â””â”€â”€ comparisons/                               # Model comparisons
â”‚
â””â”€â”€ ğŸ”§ configs/                                     # Configuration files
    â”œâ”€â”€ data.yaml                                  # Dataset config
    â””â”€â”€ training_configs/                          # Hyperparameters
```

---

## ğŸ““ Notebooks Description

### 1ï¸âƒ£ Data Preparation & EDA

**Notebook**: `01-data-preparation-eda.ipynb`

| Aspect | Details |
|--------|---------|
| **Purpose** | Dataset splitting and exploratory data analysis |
| **Split Ratio** | 80% Train / 10% Validation / 10% Test |
| **Total Images** | ~1,200 Brain MRI scans |
| **Classes** | CCT, IFC, UAS (3 classes) |
| **Format** | YOLO annotation format |

**Key Outputs:**
- Class distribution visualization
- Image size analysis
- Bounding box statistics
- Data quality verification

<details>
<summary>ğŸ“Š Click to view Class Distribution</summary>

```
Class Distribution:
â”œâ”€â”€ CCT: 35.2% (423 instances)
â”œâ”€â”€ IFC: 32.8% (394 instances)
â””â”€â”€ UAS: 32.0% (384 instances)

Split Statistics:
â”œâ”€â”€ Train: 960 images
â”œâ”€â”€ Validation: 120 images
â””â”€â”€ Test: 120 images
```
</details>

---

### 2ï¸âƒ£ Semi-Supervised Object Detection (SSOD)

**Notebook**: `02-ssod-yolo-pseudolabel.ipynb`

| Component | Configuration |
|-----------|--------------|
| **Base Model** | YOLOv12 |
| **Labeled Data** | 20% of training set |
| **Unlabeled Data** | 80% of training set |
| **Confidence Threshold (Ï„)** | 0.70 |
| **Teacher Epochs** | 100 |
| **Student Epochs** | 100 |

**Pipeline Architecture:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Labeled Data   â”‚â”€â”€â”€â”€â–¶â”‚  Teacher Model   â”‚â”€â”€â”€â”€â–¶â”‚ Pseudo Labels   â”‚
â”‚    (20%)        â”‚     â”‚  (YOLOv12)       â”‚     â”‚  (Ï„ â‰¥ 0.70)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                          â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
                        â”‚  Student Model   â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ (Combined Data)  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Results:**

| Model | mAP@50 | Improvement |
|-------|:------:|:-----------:|
| Teacher (20% data) | 81.84% | Baseline |
| Student (Pseudo-labeled) | 73.66% | -8.18% |
| Baseline (100% data) | 93.04% | Reference |

---

### 3ï¸âƒ£ SimCLR Self-Supervised Pretraining

**Notebook**: `03-1-simclr-pretraining.ipynb`

| Hyperparameter | Value |
|----------------|-------|
| **Backbone** | ResNet-18 |
| **Projection Dim** | 128 |
| **Temperature** | 0.07 |
| **Batch Size** | 32 |
| **Epochs** | 100 |
| **Optimizer** | Adam |
| **Learning Rate** | 0.001 (cosine decay) |

**SimCLR Framework:**
```
                    Image x
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Aug t  â”‚                 â”‚  Aug t' â”‚
    â”‚ (view1) â”‚                 â”‚ (view2) â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚                           â”‚
         â–¼                           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  f(Â·)   â”‚   Encoder       â”‚  f(Â·)   â”‚
    â”‚ ResNet  â”‚   (shared)      â”‚ ResNet  â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚ h_i                       â”‚ h_j
         â–¼                           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  g(Â·)   â”‚   Projection    â”‚  g(Â·)   â”‚
    â”‚   MLP   â”‚   (shared)      â”‚   MLP   â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚ z_i                       â”‚ z_j
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
              NT-Xent Loss
```

**Training Progress:**

| Epoch | Loss | Learning Rate |
|:-----:|:----:|:-------------:|
| 1 | 3.592 | 0.00100 |
| 25 | 1.236 | 0.00086 |
| 50 | 0.989 | 0.00052 |
| 75 | 0.779 | 0.00015 |
| 100 | 0.701 | 0.00000 |

---

### 4ï¸âƒ£ SimCLR Fine-tuning

**Notebook**: `03-2-simclr-finetuning.ipynb`

| Evaluation Protocol | Description |
|---------------------|-------------|
| **Linear Evaluation** | Frozen encoder, train linear classifier only |
| **Full Fine-tuning** | Train entire network (encoder + classifier) |

**Results:**

| Protocol | Accuracy | Precision | Recall | F1-Score |
|----------|:--------:|:---------:|:------:|:--------:|
| Linear Evaluation | 58.59% | 56.81% | 58.59% | 54.60% |
| **Full Fine-tuning** | **90.31%** | **90.33%** | **90.31%** | **90.31%** |

**YOLOv12 Integration:**
- SimCLR backbone used to initialize YOLO encoder
- Detection performance: mAP@50 = 89.2%

---

### 5ï¸âƒ£ DINOv3 Feature Extraction

**Notebook**: `04-1-dinov3-featureextraction.ipynb`

| Configuration | Value |
|---------------|-------|
| **Model** | DINOv3 ViT-B/16 |
| **Parameters** | 86M |
| **Feature Dimension** | 768 |
| **Pretraining Data** | 1.7B images (LVD-1689M) |
| **Source** | Meta AI / Hugging Face |

**DINOv3 Architecture:**
```
                    Input Image
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                             â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Global   â”‚                 â”‚  Local    â”‚
   â”‚  Views    â”‚                 â”‚  Views    â”‚
   â”‚ (224Ã—224) â”‚                 â”‚ (96Ã—96)   â”‚
   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â”‚                             â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Vision         â”‚
              â”‚  Transformer    â”‚
              â”‚  + Gram Anchor  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  [CLS] Token    â”‚
              â”‚  Feature (768d) â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Feature Statistics:**

| Split | Samples | Feature Shape |
|-------|:-------:|:-------------:|
| Train | 960 | (960, 768) |
| Validation | 120 | (120, 768) |
| Test | 120 | (120, 768) |

---

### 6ï¸âƒ£ DINOv3 Fine-tuning

**Notebook**: `04-2-dinov3-finetuning.ipynb`

**Evaluation Protocols:**

| Method | Architecture | Accuracy |
|--------|--------------|:--------:|
| Linear (LogReg) | Logistic Regression | 85.23% |
| k-NN | k=5 Nearest Neighbors | 82.67% |
| **MLP Classifier** | 768â†’256â†’128â†’3 | **89.45%** |

**YOLOv12 Integration Results:**

| Epoch | mAP@50 | Precision | Recall |
|:-----:|:------:|:---------:|:------:|
| 1 | 59.96% | 57.46% | 76.54% |
| 5 | 77.41% | 70.15% | 69.69% |
| 10 | 85.19% | 83.01% | 78.51% |
| 15 | 91.87% | 84.39% | 87.57% |
| **20** | **94.08%** | **86.33%** | **89.49%** |

---

## ğŸ”¬ Methodology

### Semi-Supervised Learning Pipeline

```
Input: Labeled set DL (20%), Unlabeled set DU (80%)

1. TEACHER TRAINING
   â””â”€â”€ Train YOLOv12 on DL for 100 epochs
   â””â”€â”€ Output: Teacher weights WT

2. PSEUDO-LABEL GENERATION
   â””â”€â”€ For each image x âˆˆ DU:
       â””â”€â”€ y_pseudo = Teacher(x)
       â””â”€â”€ If confidence â‰¥ Ï„ (0.70):
           â””â”€â”€ Add (x, y_pseudo) to DPseudo

3. STUDENT TRAINING
   â””â”€â”€ Combine DL + DPseudo
   â””â”€â”€ Train YOLOv12 for 100 epochs
   â””â”€â”€ Output: Final detector WS
```

### Self-Supervised Learning Pipeline

```
STAGE 1: PRETRAINING (Unlabeled Data)
â”œâ”€â”€ SimCLR: Contrastive learning with NT-Xent loss
â””â”€â”€ DINOv3: Self-distillation with Gram anchoring

STAGE 2: FINE-TUNING (Labeled Data)
â”œâ”€â”€ Linear Evaluation: Freeze encoder, train classifier
â”œâ”€â”€ Full Fine-tuning: Train entire network
â””â”€â”€ YOLO Integration: Initialize detector backbone
```

---

## ğŸ“Š Results & Metrics

### Training Curves

#### SimCLR Pretraining Loss
```
Loss
  â”‚
4.0â”œâ”€â”€â—
   â”‚   â•²
3.0â”œâ”€â”€â”€â”€â•²
   â”‚     â•²
2.0â”œâ”€â”€â”€â”€â”€â”€â•²
   â”‚       â•²___
1.0â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²____
   â”‚                â•²____â—
0.0â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   0    25    50    75   100  Epochs
```

#### DINOv3 + YOLO Detection mAP
```
mAP@50
   â”‚
95%â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—
   â”‚                 â—â”€â”€â”€â•±
90%â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â•±
   â”‚        â—â”€â”€â”€â•±
85%â”œâ”€â”€â”€â”€â—â”€â”€â”€â•±
   â”‚â—â”€â”€â”€â•±
80%â”œâ”€â”€â•±
   â”‚â•±
75%â”œ
   0   4   8   12   16   20  Epochs
```

### Confusion Matrices

| Predicted â†’ | CCT | IFC | UAS |
|:-----------:|:---:|:---:|:---:|
| **CCT** | 93% | 4% | 3% |
| **IFC** | 5% | 91% | 4% |
| **UAS** | 3% | 5% | 92% |

*DINOv3 + YOLO Detector Confusion Matrix*

---

## ğŸ“¸ Visualizations

### Feature Space Visualization (t-SNE)

The t-SNE plots show clear cluster separation after self-supervised pretraining:

| Before Fine-tuning | After Fine-tuning |
|:------------------:|:-----------------:|
| Mixed clusters | Clear separation |
| Overlapping classes | Distinct boundaries |

### Sample Detection Results

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ§  Brain MRI Detection Results        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”   â”‚  â”‚ â”Œâ”€â”€â”€â”€â”   â”‚           â”‚
â”‚  â”‚ â”‚CCT â”‚   â”‚  â”‚ â”‚IFC â”‚   â”‚           â”‚
â”‚  â”‚ â”‚95% â”‚   â”‚  â”‚ â”‚93% â”‚   â”‚           â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”˜   â”‚  â”‚ â””â”€â”€â”€â”€â”˜   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚     Image 1       Image 2             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Installation & Usage

### Prerequisites

```bash
# Python 3.8+
python --version

# CUDA 11.8+ (for GPU support)
nvidia-smi
```

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/CSE475_Assignment2_SSL.git
cd CSE475_Assignment2_SSL

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
venv\Scripts\activate     # Windows

# Install dependencies
pip install -r requirements.txt
```

### Running Notebooks

```bash
# Start Jupyter
jupyter notebook

# Or use JupyterLab
jupyter lab
```

### Quick Inference

```python
from ultralytics import YOLO

# Load trained model
model = YOLO('weights/yolo_detectors/dinov3_yolo_best.pt')

# Run inference
results = model('path/to/brain_mri.jpg')

# Display results
results[0].show()
```

---

## ğŸ‹ï¸ Model Weights

| Model | File | Size | Description |
|-------|------|:----:|-------------|
| SimCLR Backbone | `simclr_backbone.pth` | ~45 MB | Pretrained ResNet-18 |
| SimCLR Fine-tuned | `simclr_finetuned.pth` | ~45 MB | Classification model |
| DINOv3 MLP | `dinov3_mlp_best.pth` | ~5 MB | MLP classifier |
| YOLO Baseline | `baseline_best.pt` | ~22 MB | 100% labeled data |
| YOLO SSOD | `ssod_student.pt` | ~22 MB | Pseudo-label trained |
| YOLO DINOv3 | `dinov3_yolo_best.pt` | ~22 MB | **Best detector** |

---

## ğŸ“š References

1. **SimCLR**: Chen, T., et al. "A Simple Framework for Contrastive Learning of Visual Representations." ICML 2020.

2. **DINOv3**: Oquab, M., et al. "DINOv3: Learning Robust Visual Features without Supervision." arXiv 2025.

3. **YOLO**: Ultralytics. "YOLOv12: Real-Time Object Detection." 2024.

4. **Pseudo-Labeling**: Lee, D.H. "Pseudo-Label: The Simple and Efficient Semi-Supervised Learning Method." ICML Workshop 2013.

5. **STAC**: Sohn, K., et al. "A Simple Semi-Supervised Learning Framework for Object Detection." arXiv 2020.

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¤ Author

**Your Name**  
East West University  
CSE 475 - Pattern Recognition and Neural Networks  
December 2025

---

## ğŸ™ Acknowledgments

- Course Instructor for providing the assignment framework
- Ultralytics for YOLOv12 implementation
- Meta AI for DINOv3 pretrained models
- Hugging Face for Transformers library

---

<div align="center">

**â­ If you found this project helpful, please give it a star! â­**

</div>
