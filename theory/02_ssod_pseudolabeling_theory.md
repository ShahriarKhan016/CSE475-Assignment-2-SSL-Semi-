# üî¨ Notebook 02: Semi-Supervised Object Detection (SSOD) with Pseudo-Labeling

## Overview

This notebook implements a **Semi-Supervised Object Detection (SSOD)** pipeline using **Pseudo-Labeling** with **YOLOv12**. The approach leverages both labeled and unlabeled data to improve object detection performance, particularly valuable in medical imaging where annotation is expensive.

---

## üéØ Objectives

1. **Implement Teacher-Student Framework**: Train teacher on labeled data, generate pseudo-labels
2. **Leverage Unlabeled Data**: Use 80% unlabeled data with pseudo-labels
3. **Evaluate Performance**: Compare baseline vs. semi-supervised approaches
4. **Analyze Pseudo-Label Quality**: Confidence filtering and noise analysis

---

## üìê Theory & Background

### Semi-Supervised Learning (SSL)

Semi-Supervised Learning bridges the gap between supervised and unsupervised learning by utilizing both labeled and unlabeled data.

**Key Insight**: In many domains, obtaining labels is expensive (requires experts), but unlabeled data is abundant.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    DATA AVAILABILITY                             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                  ‚îÇ
‚îÇ  Labeled Data (Expensive)     Unlabeled Data (Cheap)            ‚îÇ
‚îÇ  ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     ‚îÇ
‚îÇ       20%                              80%                       ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Semi-Supervised Learning: USE BOTH!                            ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Pseudo-Labeling

Pseudo-labeling is a simple yet effective semi-supervised technique:

1. **Train on Labeled Data**: Create a "teacher" model
2. **Generate Pseudo-Labels**: Use teacher to predict labels for unlabeled data
3. **Filter by Confidence**: Keep only high-confidence predictions
4. **Retrain with Combined Data**: Train "student" on labeled + pseudo-labeled data

### Mathematical Formulation

Given:
- Labeled set: $D_L = \{(x_i, y_i)\}_{i=1}^{N_L}$
- Unlabeled set: $D_U = \{x_j\}_{j=1}^{N_U}$

The pseudo-labeling process:

$$\hat{y}_j = \text{Teacher}(x_j) \quad \text{if} \quad \max(p(y|x_j)) \geq \tau$$

Where $\tau$ is the confidence threshold.

### STAC Framework

Our implementation follows **STAC** (Self-Training Approach for Classification) adapted for object detection:

```
Algorithm: STAC for Object Detection
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Input: DL (labeled), DU (unlabeled), œÑ (threshold)
Output: Final detector model

1. Train Teacher on DL
2. For each x ‚àà DU:
   a. predictions = Teacher(x)
   b. For each bbox in predictions:
      if confidence ‚â• œÑ:
         Add bbox to pseudo-labels
3. Combine DL and pseudo-labeled DU
4. Train Student on combined data
5. Return Student model
```

---

## üîß Configuration

### Hyperparameters

| Parameter | Value | Justification |
|-----------|:-----:|---------------|
| Labeled Ratio | 20% | Simulate limited labels |
| Confidence Threshold (œÑ) | 0.70 | Balance precision/recall |
| Teacher Epochs | 100 | Sufficient convergence |
| Student Epochs | 100 | Match teacher training |
| Image Size | 640 | YOLO standard |
| Batch Size | 16 | Memory efficient |
| IoU Threshold | 0.45 | NMS parameter |

### Confidence Threshold Selection

The threshold œÑ = 0.70 was chosen based on:

```
Threshold Analysis:
‚îú‚îÄ‚îÄ œÑ = 0.50: High recall, low precision (noisy labels)
‚îú‚îÄ‚îÄ œÑ = 0.70: Balanced trade-off ‚úì
‚îú‚îÄ‚îÄ œÑ = 0.90: High precision, low recall (few pseudo-labels)
‚îî‚îÄ‚îÄ œÑ = 0.95: Very few pseudo-labels
```

---

## üèóÔ∏è Architecture

### Teacher-Student Framework

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     PSEUDO-LABELING PIPELINE                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                      ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                               ‚îÇ
‚îÇ   ‚îÇ  Labeled Data   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                        ‚îÇ
‚îÇ   ‚îÇ     (20%)       ‚îÇ      ‚îÇ                                        ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚ñº                                        ‚îÇ
‚îÇ                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                ‚îÇ
‚îÇ                       ‚îÇ   TEACHER   ‚îÇ                                ‚îÇ
‚îÇ                       ‚îÇ  (YOLOv12)  ‚îÇ                                ‚îÇ
‚îÇ                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                ‚îÇ
‚îÇ                              ‚îÇ                                       ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ   ‚îÇ Unlabeled Data  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Pseudo-Labels     ‚îÇ         ‚îÇ
‚îÇ   ‚îÇ     (80%)       ‚îÇ        ‚îÇ        ‚îÇ (Confidence ‚â• œÑ)  ‚îÇ         ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                              ‚îÇ                  ‚îÇ                    ‚îÇ
‚îÇ                              ‚îÇ                  ‚îÇ                    ‚îÇ
‚îÇ                              ‚ñº                  ‚ñº                    ‚îÇ
‚îÇ                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
‚îÇ                       ‚îÇ     COMBINED DATASET        ‚îÇ               ‚îÇ
‚îÇ                       ‚îÇ  (Labeled + Pseudo-Labeled) ‚îÇ               ‚îÇ
‚îÇ                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ                                      ‚îÇ                               ‚îÇ
‚îÇ                                      ‚ñº                               ‚îÇ
‚îÇ                               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ
‚îÇ                               ‚îÇ   STUDENT   ‚îÇ                        ‚îÇ
‚îÇ                               ‚îÇ  (YOLOv12)  ‚îÇ                        ‚îÇ
‚îÇ                               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### YOLOv12 Architecture

```
Input (640√ó640√ó3)
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    Backbone     ‚îÇ ‚Üê CSP-Darknet
‚îÇ  (Feature Ext.) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      Neck       ‚îÇ ‚Üê PANet
‚îÇ (Feature Fusion)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚ñº    ‚ñº    ‚ñº
   P3   P4   P5    ‚Üê Multi-scale predictions
    ‚îÇ    ‚îÇ    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚ñº
   Detection Heads
   (Class + BBox)
```

---

## üìä Results

### Model Performance Comparison

| Model | mAP@50 | mAP@50-95 | Precision | Recall | F1 |
|-------|:------:|:---------:|:---------:|:------:|:--:|
| **Baseline (100% data)** | **93.04%** | **64.59%** | 84.66% | 86.55% | 85.59% |
| Teacher (20% data) | 81.84% | 53.92% | 72.11% | 79.34% | 75.55% |
| Student (Pseudo-labeled) | 73.66% | 49.55% | 71.19% | 69.08% | 70.12% |

### Per-Class Performance (AP@50)

| Class | Baseline | Teacher | Student |
|-------|:--------:|:-------:|:-------:|
| CCT | 95.18% | 77.37% | 76.53% |
| IFC | 91.89% | 76.30% | 60.15% |
| UAS | 92.06% | 91.85% | 84.29% |

### Pseudo-Label Statistics

```
Pseudo-Label Analysis:
‚îú‚îÄ‚îÄ Total unlabeled images: 768
‚îú‚îÄ‚îÄ Images with pseudo-labels: 623 (81.1%)
‚îú‚îÄ‚îÄ Total pseudo-labels generated: 847
‚îú‚îÄ‚îÄ Average confidence: 0.82
‚îú‚îÄ‚îÄ Confidence distribution:
‚îÇ   ‚îú‚îÄ‚îÄ 0.70-0.80: 34%
‚îÇ   ‚îú‚îÄ‚îÄ 0.80-0.90: 41%
‚îÇ   ‚îî‚îÄ‚îÄ 0.90-1.00: 25%
‚îî‚îÄ‚îÄ Class distribution of pseudo-labels:
    ‚îú‚îÄ‚îÄ CCT: 38%
    ‚îú‚îÄ‚îÄ IFC: 31%
    ‚îî‚îÄ‚îÄ UAS: 31%
```

---

## üîç Analysis & Discussion

### Why Did Student Underperform?

The student model showed lower performance than expected. Key factors:

1. **Label Noise**: Some pseudo-labels are incorrect despite high confidence
2. **Distribution Mismatch**: Pseudo-label distribution differs from true distribution
3. **Confirmation Bias**: Teacher errors propagate to student
4. **Limited Teacher Capacity**: 20% data may be insufficient for quality pseudo-labels

### Potential Improvements

```
Future Directions:
‚îú‚îÄ‚îÄ 1. Iterative Refinement: Multiple teacher-student cycles
‚îú‚îÄ‚îÄ 2. Soft Labels: Use probability distributions instead of hard labels
‚îú‚îÄ‚îÄ 3. EMA Teacher: Exponential moving average of student weights
‚îú‚îÄ‚îÄ 4. Consistency Regularization: Augmentation-invariant predictions
‚îî‚îÄ‚îÄ 5. Higher Threshold: œÑ = 0.80 or 0.85 for cleaner pseudo-labels
```

---

## üìà Training Curves

### Teacher Training

```
Loss vs Epoch (Teacher)
‚îÇ
‚îÇ  ‚óè
4.0‚îú‚îÄ‚îÄ‚ï≤
   ‚îÇ   ‚ï≤
3.0‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚ï≤
   ‚îÇ     ‚ï≤
2.0‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï≤
   ‚îÇ       ‚ï≤___
1.0‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï≤____
   ‚îÇ                ‚ï≤____‚óè
0.0‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   0    25    50    75   100
                        Epoch
```

### Student Training

```
mAP@50 vs Epoch (Student)
‚îÇ
80%‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óè
   ‚îÇ              ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï±
70%‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï±
   ‚îÇ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï±
60%‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï±
   ‚îÇ
50%‚îú
   0    25    50    75   100
                        Epoch
```

---

## üõ†Ô∏è Implementation Highlights

### Pseudo-Label Generation

```python
def generate_pseudo_labels(model, dataloader, confidence_threshold=0.70):
    """Generate pseudo-labels from unlabeled data."""
    pseudo_labels = {}
    
    for images, image_paths in dataloader:
        predictions = model.predict(images, conf=confidence_threshold)
        
        for pred, path in zip(predictions, image_paths):
            boxes = pred.boxes
            if len(boxes) > 0:
                # Filter by confidence
                confident_mask = boxes.conf >= confidence_threshold
                confident_boxes = boxes[confident_mask]
                
                if len(confident_boxes) > 0:
                    pseudo_labels[path] = confident_boxes
    
    return pseudo_labels
```

### Combined Dataset Creation

```python
def create_combined_dataset(labeled_dir, pseudo_labels, output_dir):
    """Combine labeled data with pseudo-labeled data."""
    # Copy labeled data
    shutil.copytree(labeled_dir, output_dir)
    
    # Add pseudo-labeled data
    for image_path, labels in pseudo_labels.items():
        # Copy image
        shutil.copy(image_path, output_dir / 'images')
        
        # Write pseudo-labels in YOLO format
        label_path = output_dir / 'labels' / f'{image_path.stem}.txt'
        with open(label_path, 'w') as f:
            for box in labels:
                # class_id x_center y_center width height
                f.write(f'{int(box.cls)} {box.xywhn}\n')
```

---

## üìö References

1. Lee, D.H. "Pseudo-Label: The Simple and Efficient Semi-Supervised Learning Method for Deep Neural Networks." ICML Workshop 2013.

2. Sohn, K., et al. "A Simple Semi-Supervised Learning Framework for Object Detection." arXiv 2020 (STAC).

3. Xu, M., et al. "End-to-End Semi-Supervised Object Detection with Soft Teacher." ICCV 2021.

4. Liu, Y.C., et al. "Unbiased Teacher for Semi-Supervised Object Detection." ICLR 2021.

---

## üîë Key Takeaways

1. **Semi-Supervised Learning** can leverage unlabeled data effectively
2. **Confidence Threshold** is critical for pseudo-label quality
3. **Teacher-Student Framework** provides a structured approach
4. **Performance Gap** exists between fully supervised and semi-supervised
5. **Future Work**: Advanced techniques like Soft Teacher could improve results

---

## ‚ñ∂Ô∏è Next Steps

After completing SSOD, proceed to:
- **Notebook 03-1**: SimCLR Self-Supervised Pretraining
- **Notebook 04-1**: DINOv3 Feature Extraction
