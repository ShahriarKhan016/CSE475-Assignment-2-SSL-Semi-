% ============================================================================
% LITERATURE REVIEW
% ============================================================================
\section{Literature Review}
\label{sec:literature}

\sloppy

Deep learning has revolutionized medical image analysis, with object detection methods achieving remarkable success in identifying and localizing pathologies across various imaging modalities. The following subsections examine key advances in object detection architectures, their applications to medical imaging, and emerging paradigms in semi-supervised and self-supervised learning.

\subsection{Object Detection Architectures}

\subsubsection{Evolution of Detection Methods}
Region-based Convolutional Neural Networks (R-CNN) introduced the two-stage detection paradigm, where region proposals are generated first, followed by classification \citep{girshick2014rich}. Fast R-CNN improved efficiency through shared convolutional features \citep{girshick2015fast}, while Faster R-CNN introduced the Region Proposal Network (RPN) for end-to-end training \citep{ren2015faster}. These methods have been successfully applied to medical imaging tasks including lesion detection in DeepLesion \citep{yan2018deeplesion}.

\subsubsection{Single-Stage Detectors}
YOLO (You Only Look Once) pioneered single-stage detection, framing detection as a regression problem with unified architecture \citep{redmon2016yolo}. YOLOv2 introduced batch normalization and anchor boxes \citep{redmon2017yolo9000}, YOLOv3 added multi-scale predictions through Feature Pyramid Networks \citep{redmon2018yolov3}, and YOLOv4 incorporated CSPDarknet backbone and PANet neck \citep{bochkovskiy2020yolov4}. Recent versions (YOLOv9-v12) incorporate attention mechanisms and transformer-inspired modules \citep{wang2024yolov9, wang2024yolov10}, achieving state-of-the-art performance while maintaining real-time inference.

\subsubsection{Transformer-Based Detection}
DETR (DEtection TRansformer) eliminated hand-designed components like anchor boxes through end-to-end transformer architecture \citep{carion2020detr}. Deformable DETR improved training efficiency and small object detection \citep{zhu2021deformable}.

\subsection{Medical Image Analysis with Deep Learning}

Brain tumor detection and segmentation using deep learning has achieved significant success. Havaei et al. \citep{havaei2017brain} demonstrated CNNs for brain tumor segmentation, while Abiwinanda et al. \citep{abiwinanda2019brain} applied CNNs to brain tumor classification. Deepak and Ameer \citep{deepak2019brain} showed transfer learning effectiveness for brain tumor classification, and Swati et al. \citep{swati2019brain} achieved state-of-the-art results using VGG-based architectures. Litjens et al. \citep{litjens2017survey} provided a comprehensive survey of deep learning in medical image analysis, establishing that transfer learning from ImageNet often outperforms training from scratch on limited medical data \citep{raghu2019transfusion}.

\subsection{Semi-Supervised Learning}

Semi-supervised learning addresses limited labeled data by leveraging unlabeled samples \citep{chapelle2009semi, zhu2009introduction}. Pseudo-labeling generates labels for unlabeled data using model predictions, then retrains on the expanded dataset \citep{lee2013pseudo}. For object detection, STAC combines pseudo-labeling with strong augmentation \citep{sohn2020simple}, while Unbiased Teacher addresses pseudo-label bias through focal loss reweighting \citep{liu2021unbiased}. Soft Teacher uses soft weighting schemes for pseudo-labels \citep{xu2021end}. FixMatch demonstrated that consistency regularization with weak-strong augmentation pairs significantly improves SSL performance \citep{sohn2020fixmatch}. Consistency regularization enforces prediction stability under perturbations \citep{sajjadi2016regularization, jeong2019consistency}.

\subsection{Self-Supervised Representation Learning}

Self-supervised learning learns representations from unlabeled data through pretext tasks \citep{jing2020self, liu2021self}. SimCLR introduced contrastive learning with strong augmentations and learnable projections \citep{chen2020simclr}. MoCo (Momentum Contrast) improved efficiency through momentum-updated encoders \citep{he2020moco, chen2020mocov2}. BYOL demonstrated that negative samples are unnecessary through self-distillation \citep{grill2020byol}, and SimSiam further simplified this approach \citep{chen2021simsiam}.

DINO applied self-distillation to Vision Transformers, learning powerful features without labels \citep{caron2021dino}. DINOv2 scaled this approach to larger datasets, learning visual features that generalize across tasks \citep{oquab2023dinov2}. Masked Autoencoders (MAE) learn by reconstructing masked patches \citep{he2022mae}, while BEiT introduced vision tokenization \citep{bao2021beit}. These methods have proven particularly effective for medical imaging where labeled data is scarce \citep{azizi2021big, sowrirajan2021moco, ciga2022self, chen2019self}.

\subsection{Comparison with Related Work}

Table \ref{tab:literature_comparison} compares our work with related studies in medical image detection and semi/self-supervised learning.

\begin{table}[htbp]
\centering
\caption{Comparison with Related Work on Medical Image Detection}
\label{tab:literature_comparison}
\footnotesize
\setlength{\tabcolsep}{3pt}
\begin{tabular}{@{}p{2.5cm}p{1.8cm}p{2.2cm}p{1.5cm}p{2.8cm}@{}}
\toprule
\textbf{Study} & \textbf{Data} & \textbf{Method} & \textbf{Perf.} & \textbf{Contribution} \\
\midrule
Havaei et al. \citep{havaei2017brain} & MRI & CNN Seg. & -- & Two-path CNN \\
Swati et al. \citep{swati2019brain} & MRI & VGG16 TL & 94.8\% & ImageNet TL \\
Deepak \citep{deepak2019brain} & MRI & GoogLeNet & 98.0\% & Deep TL \\
Liu et al. \citep{liu2021unbiased} & COCO & Unb. Teacher & 34.9\% & Focal loss \\
Sohn et al. \citep{sohn2020simple} & COCO & STAC & 28.6\% & Strong aug. \\
Azizi et al. \citep{azizi2021big} & Medical & SimCLR & +5\% & Self-sup. \\
\midrule
\textbf{Ours} & MRI & DINO+YOLO & \textbf{94.08\%} & SSL+Det. \\
\bottomrule
\end{tabular}
\end{table}

Our work differs from prior studies by: (1) systematically comparing supervised, semi-supervised, and self-supervised paradigms on the same dataset; (2) demonstrating that DINOv3 features integrated with modern YOLO detectors outperform fully supervised baselines; and (3) providing practical insights for label-efficient medical imaging applications.
